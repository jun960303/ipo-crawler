# crawler/ipo38.py

import requests
from bs4 import BeautifulSoup
from datetime import datetime
from .base import insert_ipo, get_write_conn

HEADERS = {"User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64)"}

URLS = {
    "bidding": {
        "base": "http://www.38.co.kr/html/fund/index.htm?o=k&page=",
        "summary": "ê³µëª¨ì£¼ ì²­ì•½ì¼ì •",
    },
    "bookbuilding": {
        "base": "http://www.38.co.kr/html/fund/index.htm?o=r&page=",
        "summary": "ìˆ˜ìš”ì˜ˆì¸¡ì¼ì •",
    },
    "listing": {
        "base": "http://www.38.co.kr/html/fund/index.htm?o=nw&page=",
        "summary": "ì‹ ê·œìƒì¥ì¢…ëª©",
    },
}

# ì¹´í…Œê³ ë¦¬ë³„ ìµœëŒ€ í˜ì´ì§€ (í•µì‹¬ ë°ì´í„°ë§Œ í¬ë¡¤ë§)
MAX_PAGES = {
    "bidding": 5,  # ê³µëª¨ì²­ì•½ì¼ì •: ìµœê·¼ 5í˜ì´ì§€
    "bookbuilding": 5,  # ìˆ˜ìš”ì˜ˆì¸¡ì¼ì •: ìµœê·¼ 5í˜ì´ì§€
    "listing": 3,  # ì‹ ê·œìƒì¥ì¢…ëª©: ìµœê·¼ 3í˜ì´ì§€
}


def crawl_38_all(log_func=None, stop_checker=None):
    """
    38ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ ì „ì²´ í¬ë¡¤ë§
    - ì¹´í…Œê³ ë¦¬ë³„ í˜ì´ì§€ ì œí•œ ì ìš©
    - ì˜¤ëŠ˜ ì´í›„ ì¼ì •ë§Œ DB ì €ì¥
    - stop_checker()ê°€ Trueë©´ ì¤‘ê°„ ì¢…ë£Œ
    """
    total = 0

    total += crawl_category("bidding", log_func, stop_checker)
    total += crawl_category("bookbuilding", log_func, stop_checker)
    total += crawl_category("listing", log_func, stop_checker)

    # ğŸ”¥ ëª¨ë“  INSERT ëë‚˜ê³  ë§ˆì§€ë§‰ì— commit 1ë²ˆë§Œ
    conn = get_write_conn()
    conn.commit()

    if log_func:
        log_func(f"âœ… 38ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ ì „ì²´ {total}ê±´ ì €ì¥ ì™„ë£Œ")

    return total


# ---------------------- ê³µí†µ ìœ í‹¸ ----------------------


def get_html(url):
    r = requests.get(url, headers=HEADERS, timeout=10)
    r.raise_for_status()
    return BeautifulSoup(r.text, "lxml")


def get_rows(url, summary):
    soup = get_html(url)
    table = soup.find("table", {"summary": summary})
    if not table:
        return None, 0

    rows = table.find_all("tr")[2:]  # í—¤ë” 2ì¤„ ì œì™¸
    return rows, len(rows)


# ---------------------- ì¹´í…Œê³ ë¦¬ ë°˜ë³µ ----------------------


def crawl_category(key, log_func=None, stop_checker=None):
    base = URLS[key]["base"]
    summary = URLS[key]["summary"]
    max_page = MAX_PAGES.get(key, 3)

    if log_func:
        log_func(f"â–¶ {summary} ì „ì²´ í¬ë¡¤ë§ ì‹œì‘... (ìµœëŒ€ {max_page} í˜ì´ì§€)")

    page = 1
    count_total = 0

    while page <= max_page:
        # ì¤‘ì§€ ìš”ì²­ì´ë©´ ë°”ë¡œ ì¢…ë£Œ
        if stop_checker and stop_checker():
            if log_func:
                log_func("â›” ì‚¬ìš©ì ìš”ì²­ìœ¼ë¡œ í¬ë¡¤ë§ ì¤‘ë‹¨")
            break

        url = base + str(page)
        if log_func:
            log_func(f"  â–¶ í˜ì´ì§€ {page} í¬ë¡¤ë§...")

        rows, row_count = get_rows(url, summary)

        if rows is None or row_count == 0:
            # ë” ì´ìƒ ë°ì´í„° ì—†ìœ¼ë©´ ì¢…ë£Œ
            break

        if key == "bidding":
            count_total += parse_bidding(rows)
        elif key == "bookbuilding":
            count_total += parse_bookbuilding(rows)
        else:
            count_total += parse_listing(rows)

        page += 1

    if log_func:
        log_func(f"  â”” {summary} {count_total}ê±´ ì €ì¥")

    return count_total


# ---------------------- íŒŒì‹± í•¨ìˆ˜ ----------------------


def parse_bidding(rows):
    """ê³µëª¨ì£¼ ì²­ì•½ì¼ì •"""
    count = 0
    today = datetime.now().strftime("%Y-%m-%d")

    for tr in rows:
        tds = tr.find_all("td")
        if len(tds) < 6:
            continue

        cols = [td.get_text(strip=True) for td in tds]

        stock = cols[0]
        date_range = cols[1]
        offer = cols[2]
        broker = cols[5]

        start, end = parse_range(date_range)

        # âœ… ì˜¤ëŠ˜ ì´í›„ ì¼ì •ë§Œ ì €ì¥ (ì²­ì•½ ì¢…ë£Œì¼ ê¸°ì¤€)
        if end:
            if end < today:
                continue
        elif start:
            if start < today:
                continue

        insert_ipo(
            {
                "stock_name": stock,
                "status": "ê³µëª¨ì²­ì•½",
                "lead_manager": broker,
                "brokers": broker,
                "offer_price": to_float(offer),
                "sub_start": start,
                "sub_end": end,
                "listing_date": None,
                "demand_start": None,
                "demand_end": None,
                "refund_date": None,
                "source": "ê³µëª¨ì²­ì•½ì¼ì •",
            }
        )
        count += 1
    return count


def parse_bookbuilding(rows):
    """ìˆ˜ìš”ì˜ˆì¸¡ì¼ì •"""
    count = 0
    today = datetime.now().strftime("%Y-%m-%d")

    for tr in rows:
        tds = tr.find_all("td")
        if len(tds) < 5:
            continue

        cols = [td.get_text(strip=True) for td in tds]

        stock = cols[0]
        date_range = cols[1]
        offer = cols[3] if len(cols) > 3 else None
        broker = cols[5] if len(cols) > 5 else ""

        start, end = parse_range(date_range)

        # âœ… ì˜¤ëŠ˜ ì´í›„ ì¼ì •ë§Œ ì €ì¥ (ìˆ˜ìš”ì˜ˆì¸¡ ì¢…ë£Œì¼ ê¸°ì¤€)
        if end:
            if end < today:
                continue
        elif start:
            if start < today:
                continue

        insert_ipo(
            {
                "stock_name": stock,
                "status": "ìˆ˜ìš”ì˜ˆì¸¡",
                "lead_manager": broker,
                "brokers": broker,
                "offer_price": to_float(offer),
                "sub_start": None,
                "sub_end": None,
                "listing_date": None,
                "demand_start": start,
                "demand_end": end,
                "refund_date": None,
                "source": "ìˆ˜ìš”ì˜ˆì¸¡ì¼ì •",
            }
        )
        count += 1
    return count


def parse_listing(rows):
    """ì‹ ê·œìƒì¥ì¢…ëª©"""
    count = 0
    today = datetime.now().strftime("%Y-%m-%d")

    for tr in rows:
        tds = tr.find_all("td")
        if len(tds) < 2:
            continue

        cols = [td.get_text(strip=True) for td in tds]
        stock = cols[0]
        listing_raw = cols[1]

        offer = cols[4] if len(cols) >= 5 else None
        listing_date = normalize_date(listing_raw)

        # âœ… ì˜¤ëŠ˜ ì´í›„ ìƒì¥ ì˜ˆì •ë§Œ ì €ì¥
        if listing_date and listing_date < today:
            continue

        insert_ipo(
            {
                "stock_name": stock,
                "status": "ìƒì¥",
                "lead_manager": None,
                "brokers": None,
                "offer_price": to_float(offer),
                "sub_start": None,
                "sub_end": None,
                "listing_date": listing_date,
                "demand_start": None,
                "demand_end": None,
                "refund_date": None,
                "source": "ì‹ ê·œìƒì¥ì¢…ëª©",
            }
        )

        count += 1
    return count


# ---------------------- ë‚ ì§œ/ìˆ«ì ìœ í‹¸ ----------------------


def normalize_date(text):
    if not text:
        return None
    try:
        dt = datetime.strptime(text.strip(), "%Y.%m.%d")
        return dt.strftime("%Y-%m-%d")
    except Exception:
        return None


def parse_range(text):
    if not text:
        return None, None
    text = text.replace(" ", "")

    if "~" not in text:
        return normalize_date(text), None

    start_raw, end_raw = text.split("~")
    year = start_raw.split(".")[0]

    if end_raw.count(".") == 1:
        end_raw = f"{year}.{end_raw}"

    return normalize_date(start_raw), normalize_date(end_raw)


def to_float(v):
    if not v:
        return None
    v = v.replace(",", "").replace("ì›", "").strip()
    return float(v) if v.isdigit() else None
